# Install transformers library if not already installed
!pip install transformers --quiet


import pandas as pd
import os
from datasets import Dataset
import torch
from tqdm import tqdm



test_path = "/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv"


test_df = pd.read_csv(test_path)


test_dataset = Dataset.from_pandas(test_df)


# Verify structure
print("\ncolumns:", test_dataset.column_names)
print("Sample article:", test_dataset[0]["article"][:1250])
print("Sample summary:", test_dataset[0]["highlights"])


from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

model_name = "sshleifer/distilbart-cnn-12-6"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

summarizer = pipeline(
    "summarization",
    model=model,
    tokenizer=tokenizer,
    device=0 if torch.cuda.is_available() else -1
)

# Test on sample article
sample_article = test_dataset[10]["article"].strip()[:1024]
print("\nOriginal Article:", sample_article[:1250] + "...")

summary = summarizer(
    sample_article,
    max_length=128,
    min_length=30,
    num_beams=4,
    early_stopping=True
)

print("\nGenerated Summary:", summary[0]["summary_text"])


# Parameters
batch_size = 64  # Adjust based on GPU memory
summarized_data = []

# Process in batches
for i in tqdm(range(0, len(test_dataset), batch_size)):
    batch_articles = [
        test_dataset[j]["article"].strip()[:1024] 
        for j in range(i, min(i + batch_size, len(test_dataset)))
    ]

    try:
        summaries = summarizer(
            batch_articles,
            max_length=96,
            min_length=30,
            num_beams=4,
            early_stopping=True
        )
        for original, summary in zip(batch_articles, summaries):
            summarized_data.append({
                "original_text": original,
                "summary": summary["summary_text"]
            })
    except Exception as e:
        for original in batch_articles:
            summarized_data.append({
                "original_text": original,
                "summary": f"Error: {str(e)}"
            })

# Save to CSV
df = pd.DataFrame(summarized_data)
df.to_csv("summarized_articles.csv", index=False)

print("âœ… Done! Summaries saved.")

